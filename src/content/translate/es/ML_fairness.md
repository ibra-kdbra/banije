---
title: "El dilema de la equidad de la IA: por qu√© no podemos tenerlo todo"
published: 2025-06-12
description: "Una explicaci√≥n de por qu√© las tres m√©tricas de equidad m√°s destacadas en el aprendizaje autom√°tico son mutuamente incompatibles y una mirada a un enfoque causal para construir modelos m√°s justos."
image: ''
tags: [AI, Machine Learning, Fairness, Ethics]
category: Engineering
draft: false
lang: "es"
originalSlug: "ML_fairness"
series:
    name: "AI Foundations"
    order: 3
---

Los modelos de aprendizaje autom√°tico toman cada vez m√°s decisiones cr√≠ticas sobre nuestras vidas, desde solicitudes de pr√©stamos hasta recomendaciones laborales e incluso predicciones de delitos. Pero hay un gran problema: estos modelos aprenden de datos hist√≥ricos, y esos datos a menudo est√°n llenos de sesgos sociales. Una IA entrenada con datos sesgados no s√≥lo aprende estos sesgos; puede amplificarlos.

Un famoso informe de ProPublica de 2016 revel√≥ que la herramienta de predicci√≥n de reincidencia COMPAS estaba sesgada en contra de los acusados ‚Äã‚Äãafroamericanos. Esto provoc√≥ un gran impulso en la comunidad de IA para definir y medir la "justicia". ¬øEl problema? Las tres m√©tricas de equidad m√°s destacadas son **mutuamente incompatibles**. Un art√≠culo innovador explica no s√≥lo *que* esto es cierto, sino *por qu√©* es cierto desde un nivel estructural fundamental.

---

## Las Tres Caras de la Justicia ‚öñÔ∏è

Para comprender el problema, necesitamos conocer a los principales contendientes para definir la justicia. El documento se centra en tres m√©tricas populares:

* **Paridad demogr√°fica**: esta m√©trica insiste en que las predicciones de un modelo deben ser independientes de un atributo sensible como la raza o el g√©nero. En t√©rminos simples, la tasa de resultados positivos (por ejemplo, obtener un pr√©stamo) deber√≠a ser la misma para todos los grupos.

* **Probabilidades igualadas**: esta m√©trica requiere que la precisi√≥n del modelo sea igual en diferentes grupos para cada resultado. Por ejemplo, la tasa de verdaderos positivos y la tasa de falsos positivos deben ser la misma tanto para hombres como para mujeres.

* **Paridad predictiva**: esta m√©trica garantiza que, para cualquier predicci√≥n determinada, la probabilidad de que sea correcta sea la misma para todos los grupos. Por ejemplo, si el modelo predice que una persona pagar√° un pr√©stamo, la tasa de pago real entre ese grupo deber√≠a ser consistente en todas las razas.

El "Teorema de la imposibilidad" demuestra que, excepto en casos triviales, un modelo no puede satisfacer estas tres m√©tricas al mismo tiempo. Esto ha dejado a los desarrolladores en un aprieto, oblig√°ndolos a elegir qu√© definici√≥n de justicia priorizar a expensas de los dem√°s.

---

## Una explicaci√≥n causal: por qu√© no pueden coexistir

La contribuci√≥n clave del art√≠culo es explicar esta imposibilidad utilizando **diagramas causales**. En lugar de limitarse a mirar las estad√≠sticas, examina las estructuras subyacentes de generaci√≥n de datos necesarias para cada m√©trica de equidad. Denotemos el **atributo sensible** como`A`, el **verdadero resultado** como`Y`, y la **predicci√≥n del modelo** como`≈∂`.

La relaci√≥n causal entre`A`,`Y`, y`≈∂`debe estructurarse de manera diferente para que cada m√©trica cumpla:

* Para **Paridad demogr√°fica** (`≈∂`es independiente de`A`), el camino entre la predicci√≥n y el atributo sensible se bloquea naturalmente cuando`Y`es un "colisionador".
    :::note[Causal Diagram for Demographic Parity]
    `A -> Y <- ≈∂`

    :::

* Para **Probabilidades igualadas** (`≈∂` es independiente de `A` dado `Y`), observar el resultado verdadero `Y` bloquea el camino entre `A` y `≈∂`.
    :::note[Causal Diagram for Equalized Odds]
    `A -> Y -> ≈∂`
    :::

* Para **Paridad predictiva** (`Y` es independiente de `A` dado `≈∂`), observar la predicci√≥n `≈∂` bloquea el camino.
    :::note[Causal Diagram for Predictive Parity]
    `A -> ≈∂ -> Y`
    :::

De estos diagramas se desprende claramente que la estructura fundamental de los datos necesarios para cada m√©trica es diferente y mutuamente excluyente. Simplemente no se puede tener un √∫nico proceso de generaci√≥n de datos que los satisfaga a todos simult√°neamente. El problema no es el algoritmo de aprendizaje; es una restricci√≥n fundamental de los datos mismos.

---

## Un nuevo camino a seguir: equidad a trav√©s de la correcci√≥n üí°

Entonces, si la justicia perfecta es imposible, ¬øqu√© hacemos? El autor sostiene que necesitamos cambiar el objetivo.

El aprendizaje autom√°tico est√°ndar tiene como objetivo la **Minimizaci√≥n de riesgos emp√≠ricos (ERM)**, lo que significa que el modelo es recompensado por coincidir perfectamente con las etiquetas en los datos de entrenamiento (a menudo sesgados). Pero ¬øy si el objetivo no fuera predecir la etiqueta *hist√≥rica*, sino una etiqueta *justa*?

Un nuevo marco causal que introduce una **"variable de correcci√≥n",`C`** se ha propuesto. Puedes pensar en`C`como un interruptor. Esta variable, que est√° influenciada por el atributo sensible`A`, determina si la predicci√≥n del modelo`≈∂`debe seguir la etiqueta verdadera`Y`o una funci√≥n diferente de "equidad".

:::note[Causal Diagram for Fairness Through Correction]
A -> C
C -> ≈∂
Y -> ≈∂
:::

Esencialmente, para un grupo que ha sido hist√≥ricamente favorecido, el modelo podr√≠a proceder como de costumbre (`C=1`). Pero para un grupo desfavorecido, la variable de correcci√≥n podr√≠a invertirse (`C=0`), lo que hace que el modelo se desv√≠e de los datos hist√≥ricos para producir un resultado m√°s equitativo. Este enfoque tiene varias ventajas:

* Reconoce que la justicia requiere activamente **desviarse de patrones hist√≥ricos sesgados**.
* Permite a los profesionales ajustar un hiperpar√°metro para decidir **cu√°nta desviaci√≥n se necesita** en funci√≥n de cu√°n injustos son los datos.
* Puede satisfacer versiones m√°s flexibles de paridad demogr√°fica y probabilidades igualadas juntas, condicionadas a la variable de correcci√≥n.`C`.

Al reformular el problema, este enfoque causal proporciona una poderosa herramienta para construir modelos que no s√≥lo reflejen el mundo tal como es, sino que ayuden a crear un mundo que est√© m√°s alineado con nuestras nociones cambiantes de justicia.
